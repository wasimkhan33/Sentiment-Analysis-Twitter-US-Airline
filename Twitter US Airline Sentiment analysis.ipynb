{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expanded-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "speaking-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Tweets.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fourth-imperial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                            0\n",
       "airline_sentiment                   0\n",
       "airline_sentiment_confidence        0\n",
       "negativereason                   5462\n",
       "negativereason_confidence        4118\n",
       "airline                             0\n",
       "airline_sentiment_gold          14600\n",
       "name                                0\n",
       "negativereason_gold             14608\n",
       "retweet_count                       0\n",
       "text                                0\n",
       "tweet_coord                     13621\n",
       "tweet_created                       0\n",
       "tweet_location                   4733\n",
       "user_timezone                    4820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "designing-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have no missing values in our data in required columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "diagnostic-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "weighted-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['tweet_id', 'airline_sentiment_confidence',\n",
    "       'negativereason', 'negativereason_confidence', 'airline',\n",
    "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
    "       'retweet_count','tweet_coord', 'tweet_created',\n",
    "       'tweet_location', 'user_timezone'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "entire-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "loose-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Babar\n",
      "[nltk_data]     kahn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "digital-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "checked-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string,re\n",
    "stop_words=stopwords.words('english')\n",
    "punct=string.punctuation\n",
    "lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "saved-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we perform text cleaning \n",
    "def pre_process(text):\n",
    "    #\n",
    "    text=re.sub('[^a-zA-Z]',' ',text)\n",
    "    text=text.lower()\n",
    "    token=word_tokenize(text)\n",
    "    lemma_word=[]\n",
    "    for word in token:\n",
    "        if word not in stop_words:\n",
    "            lemma_word.append(lemma.lemmatize(word))\n",
    "    final_text=\" \".join(lemma_word)\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-corpus",
   "metadata": {},
   "source": [
    "text=\"hello and if i have say hi how india running\"\n",
    "ft=pre_process(text)\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "accessible-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"processed\"]=data[\"text\"].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "needed-anniversary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                @VirginAmerica What @dhepburn said.   \n",
       "1          positive  @VirginAmerica plus you've added commercials t...   \n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "4          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                           processed  \n",
       "0                        virginamerica dhepburn said  \n",
       "1  virginamerica plus added commercial experience...  \n",
       "2  virginamerica today must mean need take anothe...  \n",
       "3  virginamerica really aggressive blast obnoxiou...  \n",
       "4                 virginamerica really big bad thing  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "conventional-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder=preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "supposed-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                @VirginAmerica What @dhepburn said.   \n",
       "1          positive  @VirginAmerica plus you've added commercials t...   \n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "4          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "                                           processed  sentiment  \n",
       "0                        virginamerica dhepburn said          1  \n",
       "1  virginamerica plus added commercial experience...          2  \n",
       "2  virginamerica today must mean need take anothe...          1  \n",
       "3  virginamerica really aggressive blast obnoxiou...          0  \n",
       "4                 virginamerica really big bad thing          0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"] = label_encoder.fit_transform(data[\"airline_sentiment\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "flexible-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer( max_features=500, stop_words=['virginamerica','unit','co','amp','dm','aa','http','flt','hr'], min_df=2,ngram_range = (1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "balanced-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(df[\"processed\"],df[\"sentiment\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "artificial-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=tfidf.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "primary-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'account',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'airway',\n",
       " 'almost',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanair flight',\n",
       " 'americanair thank',\n",
       " 'americanair thanks',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'appreciate',\n",
       " 'around',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'asked',\n",
       " 'assistance',\n",
       " 'attendant',\n",
       " 'available',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'bc',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'board',\n",
       " 'boarding',\n",
       " 'book',\n",
       " 'book flight',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'booking problem',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'broken',\n",
       " 'business',\n",
       " 'bwi',\n",
       " 'call',\n",
       " 'call back',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'cancelled',\n",
       " 'cancelled flight',\n",
       " 'cancelled flighted',\n",
       " 'cancelled flightled',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carry',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change flight',\n",
       " 'changed',\n",
       " 'charge',\n",
       " 'charlotte',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'chicago',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clt',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'company',\n",
       " 'complaint',\n",
       " 'computer',\n",
       " 'confirmation',\n",
       " 'connecting',\n",
       " 'connecting flight',\n",
       " 'connection',\n",
       " 'contact',\n",
       " 'cool',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'counting',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'customer',\n",
       " 'customer service',\n",
       " 'dallas',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dc',\n",
       " 'dca',\n",
       " 'deal',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delayed flight',\n",
       " 'delta',\n",
       " 'denver',\n",
       " 'departure',\n",
       " 'desk',\n",
       " 'destination',\n",
       " 'destinationdragons',\n",
       " 'dfw',\n",
       " 'different',\n",
       " 'direct',\n",
       " 'disappointed',\n",
       " 'done',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'else',\n",
       " 'email',\n",
       " 'employee',\n",
       " 'end',\n",
       " 'enough',\n",
       " 'error',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'ewr',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'fail',\n",
       " 'family',\n",
       " 'far',\n",
       " 'fare',\n",
       " 'fee',\n",
       " 'feel',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'first',\n",
       " 'first class',\n",
       " 'fix',\n",
       " 'fleek',\n",
       " 'fleet',\n",
       " 'fleet fleek',\n",
       " 'flight',\n",
       " 'flight attendant',\n",
       " 'flight booking',\n",
       " 'flight cancelled',\n",
       " 'flight delayed',\n",
       " 'flight flight',\n",
       " 'flight tomorrow',\n",
       " 'flighted',\n",
       " 'flighted flight',\n",
       " 'flightled',\n",
       " 'flightled flight',\n",
       " 'flightr',\n",
       " 'fll',\n",
       " 'fly',\n",
       " 'flyer',\n",
       " 'flying',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'frustrated',\n",
       " 'frustrating',\n",
       " 'full',\n",
       " 'gate',\n",
       " 'gate agent',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'get home',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'glad',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'gt',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'half',\n",
       " 'hang',\n",
       " 'happened',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hold',\n",
       " 'hold hour',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hour delay',\n",
       " 'hour hold',\n",
       " 'hour late',\n",
       " 'houston',\n",
       " 'hung',\n",
       " 'iad',\n",
       " 'idea',\n",
       " 'im',\n",
       " 'info',\n",
       " 'instead',\n",
       " 'international',\n",
       " 'issue',\n",
       " 'jet',\n",
       " 'jetblue',\n",
       " 'jetblue fleet',\n",
       " 'jetblue flight',\n",
       " 'jetblue thank',\n",
       " 'jetblue thanks',\n",
       " 'jfk',\n",
       " 'job',\n",
       " 'joke',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'know',\n",
       " 'la',\n",
       " 'landed',\n",
       " 'landing',\n",
       " 'last',\n",
       " 'last night',\n",
       " 'late',\n",
       " 'late flight',\n",
       " 'late flightr',\n",
       " 'lax',\n",
       " 'le',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaving',\n",
       " 'left',\n",
       " 'let',\n",
       " 'lga',\n",
       " 'life',\n",
       " 'like',\n",
       " 'line',\n",
       " 'link',\n",
       " 'little',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'look like',\n",
       " 'looking',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'luggage',\n",
       " 'made',\n",
       " 'make',\n",
       " 'making',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'mechanical',\n",
       " 'member',\n",
       " 'message',\n",
       " 'might',\n",
       " 'mile',\n",
       " 'min',\n",
       " 'minute',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'morning',\n",
       " 'much',\n",
       " 'na',\n",
       " 'name',\n",
       " 'need',\n",
       " 'need help',\n",
       " 'never',\n",
       " 'new',\n",
       " 'newark',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'nyc',\n",
       " 'offer',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'one',\n",
       " 'online',\n",
       " 'open',\n",
       " 'option',\n",
       " 'ord',\n",
       " 'paid',\n",
       " 'pas',\n",
       " 'passenger',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'person',\n",
       " 'philly',\n",
       " 'phl',\n",
       " 'phone',\n",
       " 'phx',\n",
       " 'pilot',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'plane',\n",
       " 'please',\n",
       " 'please help',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'pm',\n",
       " 'point',\n",
       " 'policy',\n",
       " 'poor',\n",
       " 'possible',\n",
       " 'price',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'put',\n",
       " 'question',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'rebook',\n",
       " 'rebooked',\n",
       " 'received',\n",
       " 'refund',\n",
       " 'rep',\n",
       " 'reply',\n",
       " 'request',\n",
       " 'reservation',\n",
       " 'response',\n",
       " 'return',\n",
       " 'ridiculous',\n",
       " 'right',\n",
       " 'room',\n",
       " 'row',\n",
       " 'rt',\n",
       " 'rt jetblue',\n",
       " 'rude',\n",
       " 'runway',\n",
       " 'said',\n",
       " 'san',\n",
       " 'sat',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'scheduled',\n",
       " 'seat',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seems',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'seriously',\n",
       " 'service',\n",
       " 'sfo',\n",
       " 'show',\n",
       " 'since',\n",
       " 'sit',\n",
       " 'site',\n",
       " 'sitting',\n",
       " 'snow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'southwest',\n",
       " 'southwestair',\n",
       " 'southwestair flight',\n",
       " 'southwestair thank',\n",
       " 'southwestair thanks',\n",
       " 'speak',\n",
       " 'st',\n",
       " 'staff',\n",
       " 'standby',\n",
       " 'start',\n",
       " 'status',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'still waiting',\n",
       " 'stop',\n",
       " 'stranded',\n",
       " 'stuck',\n",
       " 'suck',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'swa',\n",
       " 'system',\n",
       " 'take',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'tarmac',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'telling',\n",
       " 'terminal',\n",
       " 'terrible',\n",
       " 'th',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'thru',\n",
       " 'thx',\n",
       " 'ticket',\n",
       " 'time',\n",
       " 'today',\n",
       " 'together',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'travel',\n",
       " 'traveling',\n",
       " 'tried',\n",
       " 'trip',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'trying get',\n",
       " 'tv',\n",
       " 'tweet',\n",
       " 'twice',\n",
       " 'twitter',\n",
       " 'two',\n",
       " 'two hour',\n",
       " 'ua',\n",
       " 'unacceptable',\n",
       " 'understand',\n",
       " 'united',\n",
       " 'united flight',\n",
       " 'united thank',\n",
       " 'united thanks',\n",
       " 'united yes',\n",
       " 'update',\n",
       " 'upgrade',\n",
       " 'ur',\n",
       " 'usairways',\n",
       " 'usairways americanair',\n",
       " 'usairways flight',\n",
       " 'usairways hold',\n",
       " 'usairways thanks',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 'vacation',\n",
       " 'vega',\n",
       " 'via',\n",
       " 'voucher',\n",
       " 'wait',\n",
       " 'wait time',\n",
       " 'waited',\n",
       " 'waiting',\n",
       " 'want',\n",
       " 'way',\n",
       " 'weather',\n",
       " 'website',\n",
       " 'week',\n",
       " 'well',\n",
       " 'went',\n",
       " 'wife',\n",
       " 'wifi',\n",
       " 'without',\n",
       " 'word',\n",
       " 'work',\n",
       " 'working',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'worst airline',\n",
       " 'worst customer',\n",
       " 'would',\n",
       " 'would like',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yet']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "friendly-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "reverse-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "naughty-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.02)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(feature_set,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "conservative-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test=tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "invalid-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "radio-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "introductory-concentration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84      2788\n",
      "           1       0.63      0.28      0.39       919\n",
      "           2       0.80      0.45      0.58       685\n",
      "\n",
      "    accuracy                           0.74      4392\n",
      "   macro avg       0.73      0.57      0.60      4392\n",
      "weighted avg       0.73      0.74      0.70      4392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "structured-apple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7395264116575592\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "minor-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "incoming-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "corporate-blend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(feature_set,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "pacific-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhhat=lr.predict(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "constitutional-absolute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666211293260473\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test,yhhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "recorded-singles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86      2788\n",
      "           1       0.61      0.48      0.54       919\n",
      "           2       0.75      0.56      0.64       685\n",
      "\n",
      "    accuracy                           0.77      4392\n",
      "   macro avg       0.72      0.65      0.68      4392\n",
      "weighted avg       0.76      0.77      0.76      4392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,yhhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "rapid-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9178\n",
       "1    3099\n",
       "2    2363\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the accuracy of the model is also lower because of data set is not balanced\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-texas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlwork] *",
   "language": "python",
   "name": "conda-env-mlwork-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
